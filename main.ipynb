{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dumbnano import NanoAmpliParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize of the parser, seems to be meaningless, but it is not.\n",
    "#In OOP, initialization is a must.\n",
    "dumb = NanoAmpliParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combine_fastq will search all fastq.gz in src folder and save them into one single fastq in des folder\n",
    "#This method will return the path of the combined fastq file\n",
    "all_fastq = dumb.combine_fastq(src = \"./reads/bonito/\", \n",
    "                               des = \"./reads/1_onefastq/\"\n",
    "                               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nanoflit read the fastq file and filter out low quality reads, save the filtered reads into des folder\n",
    "#this method return the path of the filtered fastq file\n",
    "fastq_nano = dumb.nanoflit(src = './reads/1_onefastq/all.fastq',\n",
    "                           des = './reads/2_nanoflit/' ,\n",
    "                           NANOFILT_QSCORE = 8,  #recommended 7-9\n",
    "                           NANOFILT_MIN_LEN = 800, #depends on the length of your reads \n",
    "                           NANOFILT_MAX_LEN = 7000 #depends on the length of your reads\n",
    "                           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raingel/桌面/OOP_v2/dumbnano.py:206: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  BARCODE_IDX_DF = pd.read_csv(BARCODE_INDEX_FILE, sep=\"\\\\t\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n",
      "50000\n",
      "60000\n",
      "15140/60488 (25.03%) reads were demultiplexed successfully\n"
     ]
    }
   ],
   "source": [
    "#Singlebar take fastq file as input and demultiplex the reads into different files according to the barcodes\n",
    "#Barcode info should be provided in a tsv file. \n",
    "#Barcode info should have three columns: SampleID, FwIndex and RvAnchor\n",
    "#SampleID is the name of the sample\n",
    "#FwIndex is the barcode sequence that is located at the beginning of the read\n",
    "#RvAnchor is the sequence that is located at the end of the read, it is used to confirm the completeness of the read\n",
    "#mismatch_ratio_f and mismatch_ratio_r are the mismatch ratio allowed for the barcode and the anchor sequence\n",
    "#recommended mismatch ratio is 0.1, which means given a 20bp barcode, 2bp mismatch is allowed\n",
    "demultiplexed = dumb.singlebar(src = './reads/2_nanoflit/all_nano.fastq',\n",
    "                               des = './reads/3_demultiplexed/', \n",
    "                               BARCODE_INDEX_FILE=\"./reads/2023000003_barcode.tsv - 230107_barcode.tsv\", \n",
    "                               mismatch_ratio_f = 0.1, \n",
    "                               mismatch_ratio_r = 0.1\n",
    "                               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This method is used to remove the artificial sequence at the beginning and the end of the read\n",
    "#minibar or singlebar will mark the position of the barcode and the anchor sequence in lower case\n",
    "#Example:  TACTTCGTTCAGTTACGTATTGCTagttcgttaggcggctgatTGCTATGCGCGAGCTGCAAGTTTGATTATGGCTCAGGGAG......GGATGCCGAAGGCAGGGCTAGTGACTGGGTGAAGTCGTAACAAGGTAACCGTAgcagctcgcgcatagCA\n",
    "#deHead will remove the sequence before the second uppercase letter and after the second last uppercase letter\n",
    "#Start_offset and end_offset are used to adjust the position of cut off point\n",
    "#Example with start_offset = 10 and end_offset = 5, the result will be:\n",
    "#TACTTCGTTCAGTTACGTATTGCTagttcgttaggcggctgatTGCTATGCGC//GAGCTGCAAGTTTGATTATGGCTCAGGGAG......GGATGCCGAAGGCAGGGCTAGTGACTGGGTGAAGTCGTAACAAGGTAA//CCGTAgcagctcgcgcatagCA\n",
    "#                                                       GAGCTGCAAGTTTGATTATGGCTCAGGGAG......GGATGCCGAAGGCAGGGCTAGTGACTGGGTGAAGTCGTAACAAGGTAA\n",
    "deHead = dumb.deHead(src='./reads/3_demultiplexed/',\n",
    "                     des='./reads/4_deHead',\n",
    "                     start_offset=40,\n",
    "                    end_offset=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustering 2110.fas\n",
      "Number of records: 32\n",
      "abs_cluster_size:  3\n",
      "Number of clusters: 6\n",
      "Clustering 2279.fas\n",
      "Number of records: 90\n",
      "abs_cluster_size:  9\n",
      "Number of clusters: 1\n",
      "Clustering 2131.fas\n",
      "Number of records: 1078\n",
      "abs_cluster_size:  107\n",
      "Number of clusters: 3\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 21\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# HDBSCAN is a density-based clustering algorithm that automatically\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39m# determines the number of clusters and identifies noise in the data.\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39m# The `min_cluster_size` parameter specifies the minimum number of points\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[39m#In following code, min_cluster_size represents the ratio of the minimum number of reads in a cluster to the total number of reads\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[39m#default is 0.2, which means the minimum number of reads in a cluster is 0.2*total number of reads\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m cluster \u001b[39m=\u001b[39m dumb\u001b[39m.\u001b[39;49mclusters_fastas(src \u001b[39m=\u001b[39;49m \u001b[39m'\u001b[39;49m\u001b[39m./reads/4_deHead/\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[1;32m     22\u001b[0m                                des \u001b[39m=\u001b[39;49m \u001b[39m'\u001b[39;49m\u001b[39m./reads/5_clustered/\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[1;32m     23\u001b[0m                                min_cluster_size \u001b[39m=\u001b[39;49m \u001b[39m0.1\u001b[39;49m, \u001b[39m#recommended 0.1-0.3\u001b[39;49;00m\n\u001b[1;32m     24\u001b[0m                                mds\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m \u001b[39m#Produce a MDS plot to visualize the clustering result\u001b[39;49;00m\n\u001b[1;32m     25\u001b[0m                                )\n",
      "File \u001b[0;32m~/桌面/OOP_v2/dumbnano.py:382\u001b[0m, in \u001b[0;36mNanoAmpliParser.clusters_fastas\u001b[0;34m(self, src, des, min_cluster_size, mds)\u001b[0m\n\u001b[1;32m    380\u001b[0m dm_norm \u001b[39m=\u001b[39m dm \u001b[39m/\u001b[39m dm\u001b[39m.\u001b[39mmax()\n\u001b[1;32m    381\u001b[0m mds \u001b[39m=\u001b[39m MDS(n_components\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m,random_state\u001b[39m=\u001b[39m\u001b[39m5566\u001b[39m, dissimilarity\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mprecomputed\u001b[39m\u001b[39m'\u001b[39m, normalized_stress\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mauto\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 382\u001b[0m mds_results \u001b[39m=\u001b[39m mds\u001b[39m.\u001b[39;49mfit_transform(dm_norm)\n\u001b[1;32m    383\u001b[0m fig, ax \u001b[39m=\u001b[39m plt\u001b[39m.\u001b[39msubplots(figsize\u001b[39m=\u001b[39m(\u001b[39m15\u001b[39m,\u001b[39m15\u001b[39m))\n\u001b[1;32m    384\u001b[0m \u001b[39m#ax.scatter(df['PC1'], df['PC2'], c=cluster_labels, cmap='rainbow', s=18)\u001b[39;00m\n",
      "File \u001b[0;32m~/桌面/OOP_v2/.venv/lib/python3.10/site-packages/sklearn/manifold/_mds.py:613\u001b[0m, in \u001b[0;36mMDS.fit_transform\u001b[0;34m(self, X, y, init)\u001b[0m\n\u001b[1;32m    610\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdissimilarity \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39meuclidean\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    611\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdissimilarity_matrix_ \u001b[39m=\u001b[39m euclidean_distances(X)\n\u001b[0;32m--> 613\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membedding_, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstress_, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_iter_ \u001b[39m=\u001b[39m smacof(\n\u001b[1;32m    614\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdissimilarity_matrix_,\n\u001b[1;32m    615\u001b[0m     metric\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmetric,\n\u001b[1;32m    616\u001b[0m     n_components\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_components,\n\u001b[1;32m    617\u001b[0m     init\u001b[39m=\u001b[39;49minit,\n\u001b[1;32m    618\u001b[0m     n_init\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_init,\n\u001b[1;32m    619\u001b[0m     n_jobs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_jobs,\n\u001b[1;32m    620\u001b[0m     max_iter\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_iter,\n\u001b[1;32m    621\u001b[0m     verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose,\n\u001b[1;32m    622\u001b[0m     eps\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49meps,\n\u001b[1;32m    623\u001b[0m     random_state\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrandom_state,\n\u001b[1;32m    624\u001b[0m     return_n_iter\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    625\u001b[0m     normalized_stress\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnormalized_stress,\n\u001b[1;32m    626\u001b[0m )\n\u001b[1;32m    628\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membedding_\n",
      "File \u001b[0;32m~/桌面/OOP_v2/.venv/lib/python3.10/site-packages/sklearn/manifold/_mds.py:328\u001b[0m, in \u001b[0;36msmacof\u001b[0;34m(dissimilarities, metric, n_components, init, n_init, n_jobs, max_iter, verbose, eps, random_state, return_n_iter, normalized_stress)\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[39mif\u001b[39;00m effective_n_jobs(n_jobs) \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    327\u001b[0m     \u001b[39mfor\u001b[39;00m it \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n_init):\n\u001b[0;32m--> 328\u001b[0m         pos, stress, n_iter_ \u001b[39m=\u001b[39m _smacof_single(\n\u001b[1;32m    329\u001b[0m             dissimilarities,\n\u001b[1;32m    330\u001b[0m             metric\u001b[39m=\u001b[39;49mmetric,\n\u001b[1;32m    331\u001b[0m             n_components\u001b[39m=\u001b[39;49mn_components,\n\u001b[1;32m    332\u001b[0m             init\u001b[39m=\u001b[39;49minit,\n\u001b[1;32m    333\u001b[0m             max_iter\u001b[39m=\u001b[39;49mmax_iter,\n\u001b[1;32m    334\u001b[0m             verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[1;32m    335\u001b[0m             eps\u001b[39m=\u001b[39;49meps,\n\u001b[1;32m    336\u001b[0m             random_state\u001b[39m=\u001b[39;49mrandom_state,\n\u001b[1;32m    337\u001b[0m             normalized_stress\u001b[39m=\u001b[39;49mnormalized_stress,\n\u001b[1;32m    338\u001b[0m         )\n\u001b[1;32m    339\u001b[0m         \u001b[39mif\u001b[39;00m best_stress \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m stress \u001b[39m<\u001b[39m best_stress:\n\u001b[1;32m    340\u001b[0m             best_stress \u001b[39m=\u001b[39m stress\n",
      "File \u001b[0;32m~/桌面/OOP_v2/.venv/lib/python3.10/site-packages/sklearn/manifold/_mds.py:158\u001b[0m, in \u001b[0;36m_smacof_single\u001b[0;34m(dissimilarities, metric, n_components, init, max_iter, verbose, eps, random_state, normalized_stress)\u001b[0m\n\u001b[1;32m    155\u001b[0m B[np\u001b[39m.\u001b[39marange(\u001b[39mlen\u001b[39m(B)), np\u001b[39m.\u001b[39marange(\u001b[39mlen\u001b[39m(B))] \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m ratio\u001b[39m.\u001b[39msum(axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m    156\u001b[0m X \u001b[39m=\u001b[39m \u001b[39m1.0\u001b[39m \u001b[39m/\u001b[39m n_samples \u001b[39m*\u001b[39m np\u001b[39m.\u001b[39mdot(B, X)\n\u001b[0;32m--> 158\u001b[0m dis \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39msqrt((X\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39m2\u001b[39;49m)\u001b[39m.\u001b[39;49msum(axis\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m))\u001b[39m.\u001b[39msum()\n\u001b[1;32m    159\u001b[0m \u001b[39mif\u001b[39;00m verbose \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m2\u001b[39m:\n\u001b[1;32m    160\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mit: \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m, stress \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (it, stress))\n",
      "File \u001b[0;32m~/桌面/OOP_v2/.venv/lib/python3.10/site-packages/numpy/core/_methods.py:49\u001b[0m, in \u001b[0;36m_sum\u001b[0;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_sum\u001b[39m(a, axis\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, dtype\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, out\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, keepdims\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m     48\u001b[0m          initial\u001b[39m=\u001b[39m_NoValue, where\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[0;32m---> 49\u001b[0m     \u001b[39mreturn\u001b[39;00m umr_sum(a, axis, dtype, out, keepdims, initial, where)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# HDBSCAN is a density-based clustering algorithm that automatically\n",
    "# determines the number of clusters and identifies noise in the data.\n",
    "# The `min_cluster_size` parameter specifies the minimum number of points\n",
    "# required for a cluster to be formed. Any cluster with fewer points than\n",
    "# this threshold will be considered noise and labeled as such.\n",
    "\n",
    "# Setting the `min_cluster_size` parameter to a small value will allow\n",
    "# the algorithm to detect smaller clusters in the data, but it may also\n",
    "# result in more noise being included as clusters. On the other hand,\n",
    "# setting the `min_cluster_size` parameter to a large value will result\n",
    "# in fewer clusters being detected but with more confidence, as noise\n",
    "# and smaller clusters will be discarded.\n",
    "\n",
    "# It is important to choose an appropriate value for `min_cluster_size`\n",
    "# based on the characteristics of the data and the specific problem you\n",
    "# are trying to solve. \n",
    "\n",
    "#In following code, min_cluster_size represents the ratio of the minimum number of reads in a cluster to the total number of reads\n",
    "#default is 0.2, which means the minimum number of reads in a cluster is 0.2*total number of reads\n",
    "\n",
    "cluster = dumb.clusters_fastas(src = './reads/4_deHead/',\n",
    "                               des = './reads/5_clustered/',\n",
    "                               min_cluster_size = 0.1, #recommended 0.1-0.3\n",
    "                               mds=True #Produce a MDS plot to visualize the clustering result\n",
    "                               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
